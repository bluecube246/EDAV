{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied Machine Learning HW 4\n",
    "\n",
    "#### Hojin Lee (hl3328) & Hyuk Joon Kwon (hk3084)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a pretrained word-embedding (word2vec, glove or fasttext) for featurization instead of the bag-of-words model. Does this improve classification? How about combining the embedded words with the BoW model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading csv file\n",
    "wine_df_raw = pd.read_csv(r'wine-reviews/winemag-data-130k-v2.csv')\n",
    "df_us = wine_df_raw[wine_df_raw['country'] == 'US']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from spacy en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the description column from the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_trainval, y_trainval = df_us['description'], df_us['points']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change all the strings in the document to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_trainval = text_trainval.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove every character that is not either a lowercase alphabet or a space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_trainval = text_trainval.apply(lambda x : re.sub(\"[^a-z\\s]\",\"\",x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a text vector of dimention 300 for every datapoint in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words(\"english\"))\n",
    "text_trainval = text_trainval.apply(lambda x : \" \".join(word for word in x.split() if word not in stopwords ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (numberOfDataPoints, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = nlp.pipe(text_trainval)\n",
    "text_vector = np.array([text.vector for text in document])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation with using just the description column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52976692700485"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train, text_val, y_train, y_val = train_test_split(text_vector, y_trainval)\n",
    "np.mean(cross_val_score(Ridge(), text_train, y_train, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatinate the text vector with the original dataframe on Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Unnamed: 0','country','taster_twitter_handle', 'province', 'region_2', 'title']\n",
    "\n",
    "df_drop = df_us.drop(drop_cols, axis=1)\n",
    "\n",
    "X = df_drop.loc[:, df_drop.columns != 'points']\n",
    "y = df_drop['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X.reset_index(drop=True)\n",
    "X_ = pd.concat([X_, pd.DataFrame(text_vector)], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target encode the designtaion and winery columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = ce.TargetEncoder(cols=['designation','winery',]).fit(X_, y_trainval)\n",
    "X_ = te.transform(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_val, y_train, y_val = train_test_split(X_, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = text_train.dtypes == object\n",
    "\n",
    "cat_preprocessing = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='NaN'),\n",
    "    OneHotEncoder(handle_unknown='ignore'))\n",
    "\n",
    "cont_preprocessing = make_pipeline(\n",
    "    SimpleImputer())\n",
    "\n",
    "cont_preprocessing_scale = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    StandardScaler())\n",
    "\n",
    "target_encoder = make_pipeline(\n",
    "    ce.TargetEncoder()\n",
    "    , StandardScaler())\n",
    "\n",
    "te_feature = ['designation','winery']\n",
    "cont_feature = list(text_train.select_dtypes(exclude=['object']).columns)\n",
    "cat_feature = list(text_train.select_dtypes(include=['object']).columns)\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    (cont_preprocessing, cont_feature)\n",
    "    , (cat_preprocessing, cat_feature)\n",
    "    , remainder ='passthrough')\n",
    "\n",
    "preprocess_scale = make_column_transformer(\n",
    "    (cont_preprocessing_scale, cont_feature)\n",
    "    , (cat_preprocessing, cat_feature)\n",
    "    , remainder ='passthrough')\n",
    "\n",
    "cat_feature = list(set(list(text_train.select_dtypes(include=['object']).columns)) - set(te_feature))\n",
    "preprocess_scale_te = make_column_transformer(\n",
    "    (target_encoder, te_feature)\n",
    "    , (cont_preprocessing_scale, cont_feature)\n",
    "    , (cat_preprocessing, cat_feature)\n",
    "    , remainder ='passthrough')\n",
    "\n",
    "text_preprocessing = make_pipeline(\n",
    "    CountVectorizer(max_features = 5000, min_df=1, ngram_range=(1,1), stop_words='english')\n",
    "    )\n",
    "\n",
    "def pipeline_prediction(X, y, preprocess, regression):\n",
    "    OLR_pipe = make_pipeline(preprocess, regression)\n",
    "    scores_olr = cross_val_score(OLR_pipe, X, y, cv=5)\n",
    "    return np.mean(scores_olr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feature = ['description']\n",
    "cont_feature = ['price', 'designation','winery']\n",
    "cat_feature = ['region_1','taster_name', 'variety']\n",
    "\n",
    "preprocess_text = make_column_transformer(\n",
    "    (cont_preprocessing_scale, cont_feature)\n",
    "   , (cat_preprocessing, cat_feature)\n",
    "   , (text_preprocessing, 'description')\n",
    "   , remainder ='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|                   |   preprocess_text |\n",
      "|-------------------+-------------------|\n",
      "| Linear_regression |          0.741601 |\n",
      "| Ridge             |          0.762939 |\n",
      "+-------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "methods = [LinearRegression(), Ridge(alpha=10)]\n",
    "processors = [preprocess_text]\n",
    "\n",
    "method_name = ['Linear_regression', 'Ridge']\n",
    "processors_name = ['preprocess_text']\n",
    "\n",
    "processor_counter = 0\n",
    "\n",
    "for processor in processors:\n",
    "    method_counter = 0\n",
    "    results_dict[processors_name[processor_counter]] = {}\n",
    "    \n",
    "    for method in methods:\n",
    "        \n",
    "        results_dict[processors_name[processor_counter]][method_name[method_counter]] = pipeline_prediction(text_train, y_train, processor, method)\n",
    "        method_counter += 1\n",
    "        \n",
    "    processor_counter += 1\n",
    "        \n",
    "results_df = pd.DataFrame.from_dict(results_dict)\n",
    "print(tabulate(results_df, headers='keys', tablefmt='psql'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
